{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to develop possibilities in improving speech recognition system by improving accuracy and understand. It will also explore other platforms that can be used for speech recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Converting date to speech\n",
    "\n",
    "Users will be asking many forms of dates so we need to convert them into one singular form, as such we will also be defining dates beforehand so computation will be easier and errors are less likely to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See below are the defined lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHS = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\",\"july\", \"august\", \"september\",\"october\", \"november\", \"december\"]\n",
    "DAYS = [\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\"]\n",
    "DAY_EXTENTIONS = [\"rd\", \"th\", \"st\", \"nd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will write the function related "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2022, 7, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "MONTHS = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\",\"july\", \"august\", \"september\",\"october\", \"november\", \"december\"]\n",
    "DAYS = [\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\"]\n",
    "DAY_EXTENTIONS = [\"rd\", \"th\", \"st\", \"nd\"]\n",
    "def get_date(text):\n",
    "    text = text.lower()\n",
    "    today = datetime.date.today()\n",
    "\n",
    "    if text.count(\"today\") > 0:\n",
    "        return today\n",
    "\n",
    "    day = -1\n",
    "    day_of_week = -1\n",
    "    month = -1\n",
    "    year = today.year\n",
    "\n",
    "    for word in text.split():\n",
    "        if word in MONTHS:\n",
    "            month = MONTHS.index(word) + 1\n",
    "        elif word in DAYS:\n",
    "            day_of_week = DAYS.index(word)\n",
    "        elif word.isdigit():\n",
    "            day = int(word)\n",
    "        else:\n",
    "            for ext in DAY_EXTENTIONS:\n",
    "                found = word.find(ext)\n",
    "                if found > 0:\n",
    "                    try:\n",
    "                        day = int(word[:found])\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "    # THE NEW PART STARTS HERE\n",
    "    if month < today.month and month != -1:  # if the month mentioned is before the current month set the year to the next\n",
    "        year = year+1\n",
    "\n",
    "    # This is slighlty different from the video but the correct version\n",
    "    if month == -1 and day != -1:  # if we didn't find a month, but we have a day\n",
    "        if day < today.day:\n",
    "            month = today.month + 1\n",
    "        else:\n",
    "            month = today.month\n",
    "\n",
    "    # if we only found a dta of the week\n",
    "    if month == -1 and day == -1 and day_of_week != -1:\n",
    "        current_day_of_week = today.weekday()\n",
    "        dif = day_of_week - current_day_of_week\n",
    "\n",
    "        if dif < 0:\n",
    "            dif += 7\n",
    "            if text.count(\"next\") >= 1:\n",
    "                dif += 7\n",
    "\n",
    "        return today + datetime.timedelta(dif)\n",
    "\n",
    "    if day != -1:  # FIXED FROM VIDEO\n",
    "        return datetime.date(month=month, day=day, year=year)\n",
    "\n",
    "get_date(\"next friday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the entire date is converted into proper format for easier identification, even when its pure words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Explore potential in implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Enhance accuracy and speed\n",
    "Before 2023, the speech recognition module is built based on the google API. Its capabilities are limited by internet speed and microphone accuracy. \n",
    "\n",
    "Below, we will be attempting to use Vosk to understand the possibilities of offline speech recognition and its related accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally, the code will include something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyaudio #for mic access\n",
    "def listen():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening>>>\")\n",
    "        r.pause_threshold = 1\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    try:\n",
    "        print(\"Recognizing: \")\n",
    "        query = r.recognize_google(audio, language='en-in')\n",
    "        print(f\"User:  {query}\\n\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Audio not heard, plesae try again\")\n",
    "        return \"None\"\n",
    "    if query is None:\n",
    "        print(\"audio not heard at thres 2\")\n",
    "    else:\n",
    "        return query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below we will keep trying the implementation of vosk:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-l] [-f FILENAME] [-d DEVICE]\n",
      "                             [-r SAMPLERATE] [-m MODEL]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"e6b71672-5503-452a-aa99-f0136f0665bd\" --shell=9002 --transport=\"tcp\" --iopub=9004\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# prerequisites: as described in https://alphacephei.com/vosk/install and also python module `sounddevice` (simply run command `pip install sounddevice`)\n",
    "# Example usage using Dutch (nl) recognition model: `python test_microphone.py -m nl`\n",
    "# For more help run: `python test_microphone.py -h`\n",
    "\n",
    "import argparse\n",
    "import queue\n",
    "import sys\n",
    "import sounddevice as sd\n",
    "\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "q = queue.Queue()\n",
    "\n",
    "def int_or_str(text):\n",
    "    \"\"\"Helper function for argument parsing.\"\"\"\n",
    "    try:\n",
    "        return int(text)\n",
    "    except ValueError:\n",
    "        return text\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    \"\"\"This is called (from a separate thread) for each audio block.\"\"\"\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    q.put(bytes(indata))\n",
    "\n",
    "parser = argparse.ArgumentParser(add_help=False)\n",
    "parser.add_argument(\n",
    "    \"-l\", \"--list-devices\", action=\"store_true\",\n",
    "    help=\"show list of audio devices and exit\")\n",
    "args, remaining = parser.parse_known_args()\n",
    "if args.list_devices:\n",
    "    print(sd.query_devices())\n",
    "    parser.exit(0)\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=__doc__,\n",
    "    formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "    parents=[parser])\n",
    "parser.add_argument(\n",
    "    \"-f\", \"--filename\", type=str, metavar=\"FILENAME\",\n",
    "    help=\"audio file to store recording to\")\n",
    "parser.add_argument(\n",
    "    \"-d\", \"--device\", type=int_or_str,\n",
    "    help=\"input device (numeric ID or substring)\")\n",
    "parser.add_argument(\n",
    "    \"-r\", \"--samplerate\", type=int, help=\"sampling rate\")\n",
    "parser.add_argument(\n",
    "    \"-m\", \"--model\", type=str, help=\"language model; e.g. en-us, fr, nl; default is en-us\")\n",
    "args = parser.parse_args(remaining)\n",
    "\n",
    "try:\n",
    "    if args.samplerate is None:\n",
    "        device_info = sd.query_devices(args.device, \"input\")\n",
    "        # soundfile expects an int, sounddevice provides a float:\n",
    "        args.samplerate = int(device_info[\"default_samplerate\"])\n",
    "        \n",
    "    if args.model is None:\n",
    "        model = Model(lang=\"en-us\")\n",
    "    else:\n",
    "        model = Model(lang=args.model)\n",
    "\n",
    "    if args.filename:\n",
    "        dump_fn = open(args.filename, \"wb\")\n",
    "    else:\n",
    "        dump_fn = None\n",
    "\n",
    "    with sd.RawInputStream(samplerate=args.samplerate, blocksize = 8000, device=args.device,\n",
    "            dtype=\"int16\", channels=1, callback=callback):\n",
    "        print(\"#\" * 80)\n",
    "        print(\"Press Ctrl+C to stop the recording\")\n",
    "        print(\"#\" * 80)\n",
    "\n",
    "        rec = KaldiRecognizer(model, args.samplerate)\n",
    "        while True:\n",
    "            data = q.get()\n",
    "            if rec.AcceptWaveform(data):\n",
    "                print(rec.Result())\n",
    "            else:\n",
    "                print(rec.PartialResult())\n",
    "            if dump_fn is not None:\n",
    "                dump_fn.write(data)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nDone\")\n",
    "    parser.exit(0)\n",
    "except Exception as e:\n",
    "    parser.exit(type(e).__name__ + \": \" + str(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85cab9e096cbab1951b2d3a14822210bb6543dde301eda19da12202a5ce4203b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
